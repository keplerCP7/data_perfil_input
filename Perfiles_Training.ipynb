{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "conf = SparkConf().setAppName(\"Perfiles-Training\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "codpais = sys.argv[1] #'CO' # sys.argv[1] ## #'PE' \n",
    "aniocampanaproceso = sys.argv[2] #'201710' #sys.argv[2] ## #'201801'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_set = sqlContext.read.parquet(\"s3://hdata-belcorp/modelo-analitico-parquet/perfiles-input/codpais=\" + codpais + \"/aniocampanaproceso=\" + aniocampanaproceso + \"/\")\n",
    "df_data_set.registerTempTable(\"df_data_set\")\n",
    "\n",
    "df_perfil_input = sqlContext.sql(\" select '\" + codpais + \"' as codpais, '\" + aniocampanaproceso + \"' as aniocampanaproceso, * from df_data_set \")\n",
    "df_perfil_input.registerTempTable(\"perfilinput\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_perfil_input.toPandas()\n",
    "df_data[['pup_lbel']]=df_data[['pup_lbel']].astype(float)\n",
    "df_data[['pup_esika']]=df_data[['pup_esika']].astype(float)\n",
    "df_data[['pup_cyzone']]=df_data[['pup_cyzone']].astype(float)\n",
    "df_data[['pup_cp']]=df_data[['pup_cp']].astype(float)\n",
    "df_data[['pup_fg']]=df_data[['pup_fg']].astype(float)\n",
    "df_data[['pup_mq']]=df_data[['pup_mq']].astype(float)\n",
    "df_data[['pup_tc']]=df_data[['pup_tc']].astype(float)\n",
    "df_data[['pup_tf']]=df_data[['pup_tf']].astype(float)\n",
    "df_data[['pup_lbel_cp']]=df_data[['pup_lbel_cp']].astype(float)\n",
    "df_data[['pup_lbel_fg']]=df_data[['pup_lbel_fg']].astype(float)\n",
    "df_data[['pup_lbel_mq']]=df_data[['pup_lbel_mq']].astype(float)\n",
    "df_data[['pup_lbel_tc']]=df_data[['pup_lbel_tc']].astype(float)\n",
    "df_data[['pup_lbel_tf']]=df_data[['pup_lbel_tf']].astype(float)\n",
    "df_data[['pup_esika_cp']]=df_data[['pup_esika_cp']].astype(float)\n",
    "df_data[['pup_esika_fg']]=df_data[['pup_esika_fg']].astype(float)\n",
    "df_data[['pup_esika_mq']]=df_data[['pup_esika_mq']].astype(float)\n",
    "df_data[['pup_esika_tc']]=df_data[['pup_esika_tc']].astype(float)\n",
    "df_data[['pup_esika_tf']]=df_data[['pup_esika_tf']].astype(float)\n",
    "df_data[['pup_cyzone_cp']]=df_data[['pup_cyzone_cp']].astype(float)\n",
    "df_data[['pup_cyzone_fg']]=df_data[['pup_cyzone_fg']].astype(float)\n",
    "df_data[['pup_cyzone_mq']]=df_data[['pup_cyzone_mq']].astype(float)\n",
    "df_data[['pup_cyzone_tc']]=df_data[['pup_cyzone_tc']].astype(float)\n",
    "df_data[['pup_cyzone_tf']]=df_data[['pup_cyzone_tf']].astype(float)\n",
    "df_data[['ppu_lbel']]=df_data[['ppu_lbel']].astype(float)\n",
    "df_data[['ppu_esika']]=df_data[['ppu_esika']].astype(float)\n",
    "df_data[['ppu_cyzone']]=df_data[['ppu_cyzone']].astype(float)\n",
    "df_data[['ppu_cp']]=df_data[['ppu_cp']].astype(float)\n",
    "df_data[['ppu_fg']]=df_data[['ppu_fg']].astype(float)\n",
    "df_data[['ppu_mq']]=df_data[['ppu_mq']].astype(float)\n",
    "df_data[['ppu_tc']]=df_data[['ppu_tc']].astype(float)\n",
    "df_data[['ppu_tf']]=df_data[['ppu_tf']].astype(float)\n",
    "df_data[['ppu_lbel_cp']]=df_data[['ppu_lbel_cp']].astype(float)\n",
    "df_data[['ppu_lbel_fg']]=df_data[['ppu_lbel_fg']].astype(float)\n",
    "df_data[['ppu_lbel_mq']]=df_data[['ppu_lbel_mq']].astype(float)\n",
    "df_data[['ppu_lbel_tc']]=df_data[['ppu_lbel_tc']].astype(float)\n",
    "df_data[['ppu_lbel_tf']]=df_data[['ppu_lbel_tf']].astype(float)\n",
    "df_data[['ppu_esika_cp']]=df_data[['ppu_esika_cp']].astype(float)\n",
    "df_data[['ppu_esika_fg']]=df_data[['ppu_esika_fg']].astype(float)\n",
    "df_data[['ppu_esika_mq']]=df_data[['ppu_esika_mq']].astype(float)\n",
    "df_data[['ppu_esika_tc']]=df_data[['ppu_esika_tc']].astype(float)\n",
    "df_data[['ppu_esika_tf']]=df_data[['ppu_esika_tf']].astype(float)\n",
    "df_data[['ppu_cyzone_cp']]=df_data[['ppu_cyzone_cp']].astype(float)\n",
    "df_data[['ppu_cyzone_fg']]=df_data[['ppu_cyzone_fg']].astype(float)\n",
    "df_data[['ppu_cyzone_mq']]=df_data[['ppu_cyzone_mq']].astype(float)\n",
    "df_data[['ppu_cyzone_tc']]=df_data[['ppu_cyzone_tc']].astype(float)\n",
    "df_data[['ppu_cyzone_tf']]=df_data[['ppu_cyzone_tf']].astype(float)\n",
    "df_data[['pup']]=df_data[['pup']].astype(float)\n",
    "df_data[['ppu']]=df_data[['ppu']].astype(float)\n",
    "df_data[['tercilpup']]=df_data[['tercilpup']].astype(float)\n",
    "df_data[['tercilppu']]=df_data[['tercilppu']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_data\n",
    "data1 = (['pup_lbel', 'pup_esika', 'pup_cyzone'])\n",
    "data1 = data[data1]\n",
    "data2 = (['pup_cp', 'pup_fg', 'pup_mq', 'pup_tc', 'pup_tf'])\n",
    "data2 = data[data2]\n",
    "data3= (['pup_lbel_cp','pup_lbel_fg', 'pup_lbel_mq', 'pup_lbel_tc', 'pup_lbel_tf',\n",
    "            'pup_esika_cp', 'pup_esika_fg', 'pup_esika_mq', 'pup_esika_tc',\n",
    "            'pup_esika_tf', 'pup_cyzone_cp', 'pup_cyzone_fg', 'pup_cyzone_mq',\n",
    "            'pup_cyzone_tc', 'pup_cyzone_tf'])\n",
    "data3 = data[data3]\n",
    "data4 = (['ppu_lbel', 'ppu_esika', 'ppu_cyzone'])\n",
    "data4 = data[data4]\n",
    "data5 = (['ppu_cp', 'ppu_fg', 'ppu_mq', 'ppu_tc', 'ppu_tf'])\n",
    "data5 = data[data5]\n",
    "data6 = (['ppu_lbel_cp','ppu_lbel_fg', 'ppu_lbel_mq', 'ppu_lbel_tc', 'ppu_lbel_tf','ppu_esika_cp', \n",
    "            'ppu_esika_fg', 'ppu_esika_mq', 'ppu_esika_tc','ppu_esika_tf', 'ppu_cyzone_cp', 'ppu_cyzone_fg', \n",
    "            'ppu_cyzone_mq','ppu_cyzone_tc', 'ppu_cyzone_tf'])\n",
    "data6 = data[data6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdata1 = data1.sum(axis=1)\n",
    "#sumdata1.head()\n",
    "PUP_Lbel = data1[\"pup_lbel\"]\n",
    "PUP_Esika = data1[\"pup_esika\"]\n",
    "PUP_Cyzone = data1[\"pup_cyzone\"]\n",
    "\n",
    "#\"{:.2f}\".format(value)\n",
    "\n",
    "PUP_Lbel_P = PUP_Lbel/sumdata1\n",
    "\n",
    "PUP_Lbel_P = PUP_Lbel/sumdata1\n",
    "PUP_Esika_P = PUP_Esika/sumdata1\n",
    "PUP_Cyzone_P = PUP_Cyzone/sumdata1\n",
    "data_1 = pd.DataFrame({'pup_lbel':PUP_Lbel_P, 'pup_esika':PUP_Esika_P, 'pup_cyzone':PUP_Cyzone_P})\n",
    "###############################################################################################################################\n",
    "sumdata2 = data2.sum(axis=1)\n",
    "#sumdata2.head()\n",
    "\n",
    "PUP_CP = data2[\"pup_cp\"]\n",
    "PUP_FG = data2[\"pup_fg\"]\n",
    "PUP_MQ = data2[\"pup_mq\"]\n",
    "PUP_TC = data2[\"pup_tc\"]\n",
    "PUP_TF = data2[\"pup_tf\"]\n",
    "PUP_CP_P = PUP_CP/sumdata2\n",
    "PUP_FG_P = PUP_FG/sumdata2\n",
    "PUP_MQ_P = PUP_MQ/sumdata2\n",
    "PUP_TC_P = PUP_TC/sumdata2\n",
    "PUP_TF_P = PUP_TF/sumdata2\n",
    "data_2 = pd.DataFrame({'pup_cp':PUP_CP_P, 'pup_fg':PUP_FG_P, 'pup_mq':PUP_MQ_P,'pup_tc':PUP_TC_P,'pup_tf':PUP_TF_P})\n",
    "##\n",
    "data4_P  =  ((data4 - data4.min()) / (data4.max() - data4.min()))\n",
    "###\n",
    "data_5  =  ((data5 - data5.min()) / (data5.max() - data5.min()))\n",
    "##\n",
    "DataPerfil = pd.concat([data[(['codebelista'])],data_1,data_2,data4_P,data_5],axis=1)\n",
    "\n",
    "DATA = DataPerfil[(['pup_lbel','pup_cyzone','pup_cp','pup_mq','pup_tc','ppu_fg'])]\n",
    "\n",
    "DataPerfil1 = pd.concat([data_1,data_2,data4_P,data_5],axis=1)\n",
    "DataPerfil1 = DataPerfil1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = (DataPerfil1.quantile(.75)-DataPerfil1.quantile(0.25))\n",
    "MAX1 =  DataPerfil1.quantile(.75) + 1.5*(IQR)\n",
    "MAX1 = MAX1.transpose()\n",
    "MIN1 = DataPerfil1.quantile(.25) -1.5*(IQR)\n",
    "MIN1 = MIN1.transpose()\n",
    "data_trat = DataPerfil1[(DataPerfil1 >= MIN1) &  (DataPerfil1 <= MAX1)]\n",
    "data_trat = pd.concat([data[(['codebelista'])],data_trat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARACION DE DATOS (POST MODELO).\n",
    "data_CO = data_trat[data_trat.isnull().any(axis=1)]\n",
    "data_CO.shape\n",
    "##\n",
    "data_SO = data_trat.dropna()\n",
    "##\n",
    "data_SO[\"outliers\"] = 0\n",
    "data_CO[\"outliers\"] = 1\n",
    "\n",
    "Dato_filt = data_CO.append(data_SO)\n",
    "Dato_filt\n",
    "Dato_filt= Dato_filt.sort_values(['codebelista'], ascending=[True])\n",
    "\n",
    "Data_Perfil = pd.concat([DataPerfil,Dato_filt[(['outliers'])]],axis=1)\n",
    "\n",
    "Data_entre = Data_Perfil[(Data_Perfil['outliers'] == 0)]\n",
    "Data_reasig = Data_Perfil[(Data_Perfil['outliers'] == 1)]\n",
    "\n",
    "DATA = Data_entre[(['pup_lbel','pup_cyzone','pup_cp','pup_mq','pup_tc','ppu_fg'])]\n",
    "DATA_NEW = Data_reasig[(['pup_lbel','pup_cyzone','pup_cp','pup_mq','pup_tc','ppu_fg'])]\n",
    "\n",
    "df_data = sqlContext.createDataFrame(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output column features to pass ass parameter into th DF to kmeans\n",
    "vecAssembler = VectorAssembler(inputCols=['pup_lbel','pup_cyzone','pup_cp','pup_mq','pup_tc','ppu_fg'], outputCol=\"features\")\n",
    "new_df = vecAssembler.transform(df_data)\n",
    "#new_df.select(\"features\").show()\n",
    "\n",
    "#training kmeans model\n",
    "kmeans = KMeans(k=6, seed=10)  \n",
    "model = kmeans.fit(new_df.select('features'))\n",
    "\n",
    "#transformed = model.transform(new_df)\n",
    "#transformed.show()\n",
    "\n",
    "#save model: uploading model (parquet format) to S3\n",
    "model.write().overwrite().save(\"s3a://hdata-belcorp/perfiles-pickles/Modelo\"+codpais+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculating pup marcas lbel, esika, cyzone\n",
    "#df_pup_calculo = sqlContext.sql(\" Select aniocampanaexposicion, aniocampanaproceso, codpais, codebelista, \"\n",
    "#                                \" pup_lbel/(pup_lbel+pup_esika+pup_cyzone) as pup_lbel, \"\n",
    "#                                \" pup_esika/(pup_lbel+pup_esika+pup_cyzone) as pup_esika, \" \n",
    "#                                \" pup_cyzone/(pup_lbel+pup_esika+pup_cyzone) as pup_cyzone \"\n",
    "#                                \" from perfilinput \")\n",
    "#df_pup_calculo.registerTempTable(\"pup_calculo\")\n",
    "\n",
    "#calculating pup categorias cp, mq, tf\n",
    "#df_categoria_calculo =sqlContext.sql(\" Select aniocampanaexposicion, aniocampanaproceso, codpais, codebelista, \" \n",
    "#                                \" pup_cp/(pup_cp+pup_fg+pup_mq+pup_tc+pup_tf) as pup_cp, \"\n",
    "#                                \" pup_fg/(pup_cp+pup_fg+pup_mq+pup_tc+pup_tf) as pup_fg, \"\n",
    "#                                \" pup_mq/(pup_cp+pup_fg+pup_mq+pup_tc+pup_tf) as pup_mq, \"\n",
    "#                                \" pup_tc/(pup_cp+pup_fg+pup_mq+pup_tc+pup_tf) as pup_tc, \"\n",
    "#                                \" pup_tf/(pup_cp+pup_fg+pup_mq+pup_tc+pup_tf) as pup_tf  \"\n",
    "#                                \" from perfilinput \")\n",
    "#df_categoria_calculo.registerTempTable(\"categoria_calculo\")\n",
    "\n",
    "\n",
    "#calculating MIN and MAX values for ppu indicators for brand and category lbel, exika, cyzone, \n",
    "#cp, fg, mq, tc, tf\n",
    "#df_metricas_calculo = sqlContext.sql(\" select max(ppu_lbel) as ppu_lbel_max, min(ppu_lbel) as ppu_lbel_min, \" \n",
    "#                                     \" max(ppu_esika) as ppu_esika_max, min(ppu_esika) as ppu_esika_min, \" \n",
    "#                                     \" max(ppu_cyzone) as ppu_cyzone_max, min(ppu_cyzone) as ppu_cyzone_min, \" \n",
    "#                                    \" max(ppu_cp) as ppu_cp_max, min(ppu_cp) as ppu_cp_min, \"\n",
    "#                                     \" max(ppu_fg) as ppu_fg_max, min(ppu_fg) as ppu_fg_min, \"\n",
    "#                                     \" max(ppu_mq) as ppu_mq_max, min(ppu_mq) as ppu_mq_min, \"\n",
    "#                                     \" max(ppu_tc) as ppu_tc_max, min(ppu_tc) as ppu_tc_min, \"\n",
    "#                                     \" max(ppu_tf) as ppu_tf_max, min(ppu_tf) as ppu_tf_min \"\n",
    "#                                     \" from perfilinput \")\n",
    "#df_metricas_calculo.registerTempTable(\"metricas_calculo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating probability for ppup brand indicators lbel, esika, cyzone &\n",
    "#ppu category cp, fg, mq, tc, tf\n",
    "#df_homogenizacion_ppu_categoria_input = sqlContext.sql(\" Select a.aniocampanaexposicion, a.aniocampanaproceso, a.codpais, a.codebelista, \"\n",
    "#                                                       \n",
    "#                                         \" (a.ppu_lbel - (select ppu_lbel_min from metricas_calculo))/((select ppu_lbel_max from metricas_calculo) - ( select ppu_lbel_min from metricas_calculo)) as ppu_lbel, \"                                                       \n",
    "#                                         \" (a.ppu_esika - (select ppu_esika_min from metricas_calculo))/((select ppu_esika_max from metricas_calculo) - (select ppu_esika_min from metricas_calculo)) as ppu_esika, \"\n",
    "#                                         \" (a.ppu_cyzone - (select ppu_cyzone_min from metricas_calculo))/((select ppu_cyzone_max from metricas_calculo) - (select ppu_cyzone_min from metricas_calculo)) as ppu_cyzone, \"\n",
    "#                                                       \n",
    "#                                         \" (a.ppu_cp - (select ppu_cp_min from metricas_calculo))/((select ppu_cp_max from metricas_calculo) - (select ppu_cp_min from metricas_calculo)) as ppu_cp, \"\n",
    "#                                         \" (a.ppu_fg - (select ppu_fg_min from metricas_calculo))/((select ppu_fg_max from metricas_calculo) - (select ppu_fg_min from metricas_calculo)) as ppu_fg, \"\n",
    "#                                         \" (a.ppu_mq - (select ppu_mq_min from metricas_calculo))/((select ppu_mq_max from metricas_calculo) - (select ppu_mq_min from metricas_calculo)) as ppu_mq, \"\n",
    "#                                         \" (a.ppu_tc - (select ppu_tc_min from metricas_calculo))/((select ppu_tc_max from metricas_calculo) - (select ppu_tc_min from metricas_calculo)) as ppu_tc, \"\n",
    "#                                         \" (a.ppu_tf - (select ppu_tf_min from metricas_calculo))/((select ppu_tf_max from metricas_calculo) - (select ppu_tf_min from metricas_calculo)) as ppu_tf \"                                                       \n",
    "#                                         \n",
    "#                                         \" from perfilinput a \")\n",
    "#df_homogenizacion_ppu_categoria_input.registerTempTable(\"homogenizacion_ppu_categoria_input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidating final data set for kmeans\n",
    "#df_data_perfil = sqlContext.sql(\" Select a.codpais, a.aniocampanaexposicion, a.aniocampanaproceso, a.codebelista, \"\n",
    "#                                 \" b.pup_lbel, b.pup_esika, b.pup_cyzone , \"\n",
    "#                                 \" c.pup_cp, c.pup_mq, c.pup_tc, c.pup_fg, c.pup_tf, \"\n",
    "#                                 \" a.ppu_lbel, a.ppu_esika, a.ppu_cyzone , \"\n",
    "#                                 \" a.ppu_cp, a.ppu_mq, a.ppu_tc, a.ppu_fg, a.ppu_tf \"                 \n",
    "#                                 \" from homogenizacion_ppu_categoria_input a \"\n",
    "#                                 \" inner join pup_calculo b on b.aniocampanaexposicion=a.aniocampanaexposicion and \"\n",
    "#                                 \" b.aniocampanaproceso=a.aniocampanaproceso and b.codpais=a.codpais and \"\n",
    "#                                 \" b.codebelista=a.codebelista \"\n",
    "#                                 \" inner join categoria_calculo c on c.aniocampanaexposicion=a.aniocampanaexposicion and \"\n",
    "#                                 \" c.aniocampanaproceso=a.aniocampanaproceso and c.codpais=a.codpais and \"\n",
    "#                                 \" c.codebelista=a.codebelista\")\n",
    "#df_data_perfil.registerTempTable(\"data_perfil\")\n",
    "#DataPerfil1 = df_data_perfil.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IQR = df_data_perfil.approxQuantile([\"pup_lbel\", \"pup_cyzone\", \"pup_cp\", \"pup_mq\", \"pup_tc\", \"ppu_fg\"], [.75], 0.25)\n",
    "#df_IQR = sqlContext.sql(\" select (percentile_approx(pup_lbel, 0.75) - percentile_approx(pup_lbel, 0.25))  as pup_lbel, \"\n",
    "#                     \" (percentile_approx(pup_cyzone,0.75) - percentile_approx(pup_cyzone, 0.25)) as pup_cyzone, \"\n",
    "#                     \" (percentile_approx(pup_esika,0.75) - percentile_approx(pup_esika, 0.25)) as pup_esika, \"\n",
    "#                     \n",
    "#                     \" (percentile_approx(pup_cp, 0.75) - percentile_approx(pup_cp, 0.25)) as pup_cp, \"\n",
    "#                     \" (percentile_approx(pup_mq, 0.75) - percentile_approx(pup_mq, 0.25)) as pup_mq, \"\n",
    "#                     \" (percentile_approx(pup_tc, 0.75) - percentile_approx(pup_tc, 0.25)) as pup_tc, \"\n",
    "#                     \" (percentile_approx(pup_fg, 0.75) - percentile_approx(pup_fg, 0.25)) as pup_fg, \"\n",
    "#                     \" (percentile_approx(pup_tf, 0.75) - percentile_approx(pup_tf, 0.25)) as pup_tf, \"\n",
    "#                     \n",
    "#                     \" (percentile_approx(ppu_lbel, 0.75) - percentile_approx(ppu_lbel, 0.25))  as ppu_lbel, \"\n",
    "#                     \" (percentile_approx(ppu_cyzone, 0.75) - percentile_approx(ppu_cyzone, 0.25)) as ppu_cyzone, \"\n",
    "#                     \" (percentile_approx(ppu_esika, 0.75) - percentile_approx(ppu_esika, 0.25)) as ppu_esika, \"\n",
    "#                     \n",
    "#                     \" (percentile_approx(ppu_cp, 0.75) - percentile_approx(ppu_cp, 0.25)) as ppu_cp, \"\n",
    "#                     \" (percentile_approx(ppu_mq, 0.75) - percentile_approx(ppu_mq, 0.25)) as ppu_mq, \"\n",
    "#                     \" (percentile_approx(ppu_tc, 0.75) - percentile_approx(ppu_tc, 0.25)) as ppu_tc, \"                                         \n",
    "#                     \" (percentile_approx(ppu_fg, 0.75) - percentile_approx(ppu_fg, 0.25)) as ppu_fg, \"\n",
    "#                     \" (percentile_approx(ppu_tf, 0.75) - percentile_approx(ppu_tf, 0.25)) as ppu_tf \"\n",
    "#                     \n",
    "#                     \" from data_perfil \")\n",
    "\n",
    "#df_IQR.registerTempTable(\"df_IQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_max1 = sqlContext.sql(\"Select \"\n",
    "#                         \" (percentile_approx(pup_lbel, 0.75) + (1.5*(select pup_lbel from df_IQR))) as pup_lbel, \"\n",
    "#                         \" (percentile_approx(pup_esika, 0.75) + (1.5*(select pup_esika from df_IQR))) as pup_esika, \"\n",
    "#                         \" (percentile_approx(pup_cyzone, 0.75) + (1.5*(select pup_cyzone from df_IQR))) as pup_cyzone, \"\n",
    "#                         \" (percentile_approx(pup_cp, 0.75) + (1.5*(select pup_cp from df_IQR))) as pup_cp, \"\n",
    "#                       \" (percentile_approx(pup_mq, 0.75) + (1.5*(select pup_mq from df_IQR))) as pup_mq, \"\n",
    "#                         \" (percentile_approx(pup_tc, 0.75) + (1.5*(select pup_tc from df_IQR))) as pup_tc, \"\n",
    "#                         \" (percentile_approx(pup_tf, 0.75) + (1.5*(select pup_tf from df_IQR))) as pup_tf, \"\n",
    "#                         \" (percentile_approx(ppu_lbel, 0.75) + (1.5*(select ppu_lbel from df_IQR))) as ppu_lbel, \"\n",
    "#                         \" (percentile_approx(ppu_esika, 0.75) + (1.5*(select ppu_esika from df_IQR))) as ppu_esika, \"\n",
    "#                         \" (percentile_approx(ppu_cyzone, 0.75) + (1.5*(select ppu_cyzone from df_IQR))) as ppu_cyzone, \"                         \n",
    "#                         \" (percentile_approx(ppu_cp, 0.75) + (1.5*(select ppu_cp from df_IQR))) as ppu_cp, \"\n",
    "#                         \" (percentile_approx(ppu_fg, 0.75) + (1.5*(select ppu_fg from df_IQR))) as ppu_fg, \"\n",
    "#                         \" (percentile_approx(ppu_mq, 0.75) + (1.5*(select ppu_mq from df_IQR))) as ppu_mq, \"\n",
    "#                         \" (percentile_approx(ppu_tc, 0.75) + (1.5*(select ppu_tc from df_IQR))) as ppu_tc, \"\n",
    "#                         \" (percentile_approx(ppu_tf, 0.75) + (1.5*(select ppu_tf from df_IQR))) as ppu_tf \"                         \n",
    "#                         \" from data_perfil \")\n",
    "#df_max1.registerTempTable(\"df_max1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_min1 = sqlContext.sql(\"Select \"\n",
    "#                         \" (percentile_approx(pup_lbel, 0.25) - (1.5*(select pup_lbel from df_IQR))) as pup_lbel, \"\n",
    "#                         \" (percentile_approx(pup_esika, 0.25) - (1.5*(select pup_esika from df_IQR))) as pup_esika, \"\n",
    "#                         \" (percentile_approx(pup_cyzone, 0.25) - (1.5*(select pup_cyzone from df_IQR))) as pup_cyzone, \"\n",
    "#                         \" (percentile_approx(pup_cp, 0.25) - (1.5*(select pup_cp from df_IQR))) as pup_cp, \"\n",
    "#                         \" (percentile_approx(pup_fg, 0.25) - (1.5*(select pup_fg from df_IQR))) as pup_fg, \"\n",
    "#                         \" (percentile_approx(pup_mq, 0.25) - (1.5*(select pup_mq from df_IQR))) as pup_mq, \"\n",
    "#                         \" (percentile_approx(pup_tc, 0.25) - (1.5*(select pup_tc from df_IQR))) as pup_tc, \"\n",
    "#                         \" (percentile_approx(pup_tf, 0.25) - (1.5*(select pup_tf from df_IQR))) as pup_tf, \"\n",
    "#                         \" (percentile_approx(ppu_lbel, 0.25) - (1.5*(select ppu_lbel from df_IQR))) as ppu_lbel, \"\n",
    "#                         \" (percentile_approx(ppu_esika, 0.25) - (1.5*(select ppu_esika from df_IQR))) as ppu_esika, \"\n",
    "#                         \" (percentile_approx(ppu_cyzone, 0.25) - (1.5*(select ppu_cyzone from df_IQR))) as ppu_cyzone, \"                         \n",
    "#                         \" (percentile_approx(ppu_cp, 0.25) - (1.5*(select ppu_cp from df_IQR))) as ppu_cp, \"\n",
    "#                         \" (percentile_approx(ppu_fg, 0.25) - (1.5*(select ppu_fg from df_IQR))) as ppu_fg, \"\n",
    "#                         \" (percentile_approx(ppu_mq, 0.25) - (1.5*(select ppu_mq from df_IQR))) as ppu_mq, \"\n",
    "#                         \" (percentile_approx(ppu_tc, 0.25) - (1.5*(select ppu_tc from df_IQR))) as ppu_tc, \"\n",
    "#                         \" (percentile_approx(ppu_tf, 0.25) - (1.5*(select ppu_tf from df_IQR))) as ppu_tf \"                         \n",
    "#                         \" from data_perfil \")\n",
    "#df_min1.registerTempTable(\"df_min1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
